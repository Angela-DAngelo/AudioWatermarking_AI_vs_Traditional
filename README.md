# ğŸµ AudioWatermarking_AI_vs_Traditional

### Comparative Study of AI-based and Traditional Audio Watermarking Methods

This repository accompanies the research work *"Assessing Progress over a Decade of Digital Audio Watermarking Research"* (IEEE Access, 2024).

This project provides a systematic comparison between **traditional signal-processing** and **AI-based** audio watermarking methods.  
We implemented the classical **STAMP** system and benchmarked it against three state-of-the-art neural approaches - **AudioSeal**, **WavMark**, and **SilentCipher** - across diverse datasets (speech, multilingual speech, and music) and a wide range of perturbations.

---

## ğŸ’¡ Overview

Digital audio watermarking is a core technology for copyright protection, authenticity verification, and synthetic media detection.  
While recent AI-based models have been proposed for watermark embedding and detection, their actual robustness compared to traditional designs remains uncertain.

This project evaluates both paradigms under identical conditions, assessing:
- **Imperceptibility**
- **Robustness**
- **Bit recovery accuracy**

The repository includes implementations, benchmarks, and evaluation tools used in the comparative study.  
It aims to provide a **reproducible experimental framework** for researchers and practitioners interested in testing or extending audio watermarking methods under standardized conditions.

Overall, the results highlight that **classical signal-processing systems** still achieve competitive and often superior robustness compared to modern neural architectures, emphasizing the enduring value of traditional design principles in contemporary audio watermarking.


---

## ğŸ¤– Audio Watermarking Systems

- **STAMP**: **S**pectral **T**ransform-domain **A**udio **M**arking with **P**erceptual model (proposed classical system)
- **AudioSeal**: https://github.com/facebookresearch/audioseal (state-of-the-art AI-based system)
- **WavMark**: https://github.com/wavmark/wavmark (state-of-the-art AI-based system)
- **SilentCipher**: https://github.com/sony/silentcipher (state-of-the-art AI-based system)

---

## âš™ï¸ Evaluation Framework

- **Datasets:** AudioMarkBench, LibriSpeech, FMA  
- **Attacks:** Time Stretch, Gaussian Noise, Background Noise, Opus, EnCodec, Quantization, Highpass filter, Lowpass filter, Smooth, Echo, Mp3 compression 
- **Metrics:**  
  - Bit Recovery Accuracy (ACC)  
  - False Positive / Negative Rates (FPR, FNR)  
  - Audio Quality: SNR, PESQ, STOI, ViSQOL  

---

## ğŸ—‚ï¸ Repository Structure

The repository is organized into four main directories:

- **Dataset/** â€“ audio datasets used for benchmarking and evaluation (speech and music).  
- **Systems/** â€“ implementations of both classical and AI-based watermarking systems.  
- **Attacks/** â€“ signal perturbation scripts for robustness testing.  
- **QualityMetrics/** â€“ evaluation tools and scripts for measuring audio quality and imperceptibility (e.g., SNR, PESQ, STOI, ViSQOL).

```text
AudioWatermarking_AI_vs_Traditional/
â”‚
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ AudioMarkBench/          # Multilingual speech benchmark
â”‚   â”œâ”€â”€ LibriSpeech/             # English speech dataset
â”‚   â””â”€â”€ FMA/                     # Free Music Archive dataset
â”‚
â”œâ”€â”€ Systems/
â”‚   â”œâ”€â”€ STAMP/                   # Classical signal-processing system (proposed)
â”‚   â”œâ”€â”€ AudioSeal/               # AI-based sequence-to-sequence watermarking
â”‚   â”œâ”€â”€ WavMark/                 # Spectrogram-based neural watermarking
â”‚   â””â”€â”€ SilentCipher/            # Deep spectrogram watermarking with psychoacoustic model
â”‚
â”œâ”€â”€ Attacks/
â”‚   â”œâ”€â”€ apply_audio_perturbations.py
â”‚
â”œâ”€â”€ QualityMetrics/
â”‚   â”œâ”€â”€ quality_metrics_dir.py
â”‚   â””â”€â”€ visqol_evaluation.m         # Virtual Speech Quality Objective Listener
â”‚
â”œâ”€â”€ results/                     # Evaluation outputs and plots
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md

```

---

## ğŸ“˜ Reference

If you use or reference this work, please cite:

XXXXXXXXXXXXXX


---

## âš–ï¸ License
MIT License â€” see `LICENSE` file for details.

---

## ğŸ“© Contacts
Angela Dâ€™Angelo â€” Universitas Mercatorum, Rome, Italy  
ğŸ“§ angela.dangelo@unimercatorum.it  



